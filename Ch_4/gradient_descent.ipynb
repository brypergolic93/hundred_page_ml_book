{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "---\n",
    "This project is an example from Chapter 4 of the Hundred Page Machine Learning Book. It looks at linear regression of a cluster of sales data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The first cell reads the .csv file and creates a list out of each column of data, excluding the header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from csv import reader\n",
    "\n",
    "# Open csv file\n",
    "marketing_file_open = open('advertising.csv')\n",
    "marketing_data_read = reader(marketing_file_open)\n",
    "marketing_data_list = list(marketing_data_read)\n",
    "marketing_data = np.array(marketing_data_list)\n",
    "\n",
    "# segment each column into an array and convert the data from string to float\n",
    "sales = marketing_data[1:-1,3].astype(float)\n",
    "tv_ad = marketing_data[1:-1,0].astype(float)\n",
    "radio_ad = marketing_data[1:-1,1].astype(float)\n",
    "newspaper_ad = marketing_data[1:-1,2].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equations of Gradient Descent\n",
    "\n",
    "$$f(x) = wx+b$$\n",
    "\n",
    "We want to find the values of $w$ and $b$ that minimize the mean squared error:\n",
    "\n",
    "$$\n",
    "L = \\frac{1}{N} \\sum_{i=1}^N [y_i - (wx_i + b)]^2\n",
    "$$\n",
    "\n",
    "In the above equation, we are calculating the $y$ value predicted for a given value of $w$ and $b$ (provided by the user), then subtracting that from the actual value of $y_i$ at that $x_i$, then squaring it. We then sum up all of those values then divide by the number of data points. That is the mean squared error.\n",
    "\n",
    "To mimimize the mean squared error, we will take the partial derivative with respect to $w$ and $b$, for which we will need the chain rule:\n",
    "\n",
    "$$ \\frac{d}{dx} \\left[ f (g (x)) \\right] = f'(g(x)) \\cdot g'(x) $$\n",
    "\n",
    "and in our case, $ g(x) = y_i - (wx_i + b)$ and $f(x) = [g(x)]^2$. Let's start by finding the partial derivate with respect to $w$, $dL/dw$:\n",
    "\n",
    "$$ g'(w) = -x_i $$\n",
    "$$ f'(w) = 2[y_i - (wx_i + b)] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
